{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Suppress common UMAP and sklearn warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸŒŒ <font color=\"grey\"> Local2Global X - Graph Representation Learning at Scale</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"grey\">  Table of Contents</font>\n",
    "\n",
    "ğŸ—ï¸ <a href='#chapter1'>Structure</a>\n",
    "\n",
    "ğŸ“Š <a href='#chapter2'>Datasets</a>\n",
    "\n",
    "ğŸŒ <a href='#chapter3'>Graphs</a>\n",
    "\n",
    "ğŸ§© <a href='#chapter4'>Patches</a>\n",
    "\n",
    "ğŸ¯ <a href='#chapter5'>Embedding</a>\n",
    "\n",
    "ğŸ”— <a href='#chapter6'>Alignment</a>\n",
    "\n",
    "ğŸŒ³ <a href='#chapter7'>Hierarchical alignment</a>\n",
    "\n",
    "ğŸ“ˆ <a href='#chapter8'>Visualisation</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <a id='chapter1'> ğŸ—ï¸ <font color=\"grey\">Structure </font></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are five main parts to the package, organised as follows.\n",
    "\n",
    "```\n",
    "l2gv2/\n",
    "â”œâ”€â”€ datasets/\n",
    "â”œâ”€â”€ graphs/\n",
    "â”œâ”€â”€ patch/\n",
    "â”œâ”€â”€ embedding/\n",
    "â””â”€â”€ align/\n",
    "    â”œâ”€â”€ l2g/\n",
    "    â””â”€â”€ geo/\n",
    "```\n",
    "\n",
    "A brief overview of the contents:\n",
    "\n",
    "* ```datasets``` contains interfaces are provided for various common benchmark datasets. \n",
    "* ```graphs``` contains wrappers for graphs represented as lists of edges in pytorch-geometric ```data.edge_index``` format. These implemented features such as fast adjacency look-up and a variety of algorithms on graphs.\n",
    "* ```patch``` directory contains datastructures to represent patches and patch graphs, as well as methods to subdivide a graph into patches. \n",
    "* ```embedding``` contains various graph embedding methods, including Graph Autoencoders (GAE) and [Variational Graph Autoencoders (VGAE)](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.VGAE.html).\n",
    "* ```align``` contains two methods to compute the alignment of patches into a single graph embedding: eigenvalue synchronisation based on the [Local2Global](https://link.springer.com/article/10.1007/s10994-022-06285-7) algorithm, and the new method based on learning the alignment using a one-layer neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <a id='chapter2'> ğŸ“Š <font color=\"grey\">Datasets </font></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The L2GX framework provides access to multiple graph datasets spanning different domains and scales. All datasets are accessible through the unified `get_dataset()` interface and support conversion between multiple formats (PyTorch Geometric, Raphtory, Polars). In addition, all standard datasets available in PyTorch Geometric can be used.\n",
    "\n",
    "| Dataset | Type | Nodes | Edges | Features | Domain |\n",
    "|---------|------|-------|-------|----------|--------|\n",
    "| **Cora** | Static Citation | 2,708 | 10,556 | 1,433 | ğŸ“š Academic Papers |\n",
    "| **CiteSeer** | Static Citation | 3,327 | 9,104 | 3,703 | ğŸ“š Academic Papers |\n",
    "| **PubMed** | Static Citation | 19,717 | 88,648 | 500 | ğŸ“š Academic Papers |\n",
    "| **AS-733** | Temporal Network | 7,716 | 45,645 | Temporal | ğŸŒ Internet Infrastructure |\n",
    "| **DGraph** | Financial | ~3M | ~4M | Multiple | ğŸ’° Fraud Detection |\n",
    "| **Elliptic** | Bitcoin | 203,769 | 234,355 | 166 | â‚¿ Cryptocurrency |\n",
    "| **Elliptic2** | Bitcoin | 42M | 196M | 122K Subgraphs | â‚¿ Cryptocurrency |\n",
    "| **MAG240M** | Academic | 244M+ | 1.7B+ | Rich | ğŸ“ Citation Graph |\n",
    "| **ORBITAAL** | Bitcoin Temporal | 252M (1K sample) | 785M (5K sample) | Temporal + Anomaly | â‚¿ Financial Fraud |\n",
    "| **BTCGraph** | Bitcoin Temporal | 252M (100K sample) | 785M | Entity Type | â‚¿ Cryptocurrency |\n",
    "\n",
    "\n",
    "#### Dataset Details\n",
    "\n",
    "* **Cora**: The [Cora dataset](https://graphsandnetworks.com/the-cora-dataset/) is a citation network of 2,708 scientific publications divided into 7 classes. Each node has a 1,433-dimensional feature vector indicating word presence/absence. Accessed through PyTorch Geometric's [Planetoid](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.datasets.Planetoid.html) dataset.\n",
    "\n",
    "* **CiteSeer**: The [CiteSeer dataset](https://citeseerx.ist.psu.edu/) is a citation network of 3,327 scientific publications classified into 6 classes (Agents, AI, DB, IR, ML, HCI). Each node has a 3,703-dimensional feature vector. Part of the Planetoid collection, this dataset provides a slightly larger and more challenging benchmark than Cora.\n",
    "\n",
    "* **PubMed**: The [PubMed dataset](https://pubmed.ncbi.nlm.nih.gov/) is the largest Planetoid dataset with 19,717 scientific publications from the PubMed database classified into 3 diabetes-related classes. Each node has a 500-dimensional TF-IDF feature vector derived from paper abstracts. Excellent for testing scalability of graph neural network methods.\n",
    "\n",
    "* **AS-733**: The [SNAP autonomous systems AS-733](https://snap.stanford.edu/data/as-733.html) dataset contains 733 daily snapshots spanning 785 days (November 1997 to January 2000). Nodes represent autonomous systems and edges indicate communication events.\n",
    "\n",
    "* **DGraph**: [DGraph](https://dgraph.xinye.com/dataset) is a real-world financial graph for anomaly detection research. Described in [DGraph: A Large-Scale Financial Dataset for Graph Anomaly Detection](https://arxiv.org/abs/2207.03579). Requires manual download.\n",
    "\n",
    "* **Elliptic**: The [Elliptic dataset](https://www.kaggle.com/datasets/ellipticco/elliptic-data-set) maps Bitcoin transactions to licit/illicit categories. Contains 203,769 transactions with 166 features each. Used in [Anti-Money Laundering in Bitcoin](https://arxiv.org/pdf/1908.02591) research. Requires manual download from Kaggle.\n",
    "\n",
    "* **Elliptic2**: The [Elliptic 2 dataset](https://arxiv.org/abs/2404.19109) dataset consists of 49M nodes and 196M edges, representing transactactions. The graph is geared towards subgraph classification, containing 122K labelled subgraphs of bitcoin clusters.\n",
    "\n",
    "* **MAG240M**: The [MAG240M](https://ogb.stanford.edu/docs/lsc/mag240m/) dataset is a large heterogeneous academic citation graph with 244+ million nodes (papers, authors, institutions, fields) and 1.7+ billion edges. Requires the OGB library and substantial storage (~100GB).\n",
    "\n",
    "* **ORBITAAL**: The [ORBITAAL](https://www.nature.com/articles/s41597-025-04595-8) dataset is a comprehensive temporal Bitcoin transaction graph covering 13 years (2009-2021) with 252M entities and 785M transactions. Features timestamped transactions, entity types (exchanges, wallets, services, miners), and anomaly labels for financial fraud detection. Ideal for temporal graph neural networks and cryptocurrency flow analysis.\n",
    "\n",
    "* **BTCGraph**: The [Bitcoin Large Scale Transaction Graph](https://www.nature.com/articles/s41597-025-04684-8) is a large-scale, temporally annotated graph dataset representing Bitcoin transactions. The dataset comprises 252 million nodes and 785 million edges, with each node and edge timestamped for temporal analysis. The dataset contains two labeled subsets: 34,000 nodes annotated with entity types, and 100,000 Bitcoin addresses labeled with entity names and types.\n",
    "\n",
    "\n",
    "For the datasets requiring manual download, provide the path:\n",
    "```\n",
    "elliptic = get_dataset(\"Elliptic\", source_file=\"/path/to/elliptic.zip\")\n",
    "dgraph = get_dataset(\"DGraph\", source_file=\"/path/to/dgraph.zip\")\n",
    "```\n",
    "\n",
    "All datasets support conversion to different formats and follow the PyTorch Geometric convention. Temporal graphs return iterables over time slices, and graphs can be exported to Raphtory or NetworkX formats for analysis.\n",
    "\n",
    "Internally, the graphs are stored in parquet format, with the edge data and node features available as polars dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current datasets: ['as-733', 'Cora', 'CiteSeer', 'PubMed', 'DGraph', 'Elliptic', 'MAG240M', 'ORBITAAL', 'Bitcoin', 'BTC', 'btc']\n"
     ]
    }
   ],
   "source": [
    "from l2gx.datasets import get_dataset, list_available_datasets\n",
    "\n",
    "datasets = list_available_datasets()\n",
    "print(f\"Current datasets: {datasets}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cora = get_dataset(\"Cora\")\n",
    "tg_cora = cora.to(\"torch-geometric\")\n",
    "print(tg_cora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = cora.to(\"networkx\")\n",
    "labels = tg_cora.y.numpy()\n",
    "print(f\"Graph: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
    "print(f\"Labels: {len(np.unique(labels))} unique classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 21)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>alias</th><th>degree</th><th>degree_in</th><th>degree_out</th><th>total_transactions_in</th><th>total_transactions_out</th><th>min_sent</th><th>max_sent</th><th>total_sent</th><th>min_received</th><th>max_received</th><th>total_received</th><th>cluster_size</th><th>first_transaction_in</th><th>last_transaction_in</th><th>first_transaction_out</th><th>last_transaction_out</th><th>cluster_num_edges</th><th>cluster_num_cc</th><th>cluster_num_nodes_in_cc</th><th>label</th></tr><tr><td>i64</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>str</td></tr></thead><tbody><tr><td>1</td><td>920</td><td>920</td><td>null</td><td>3030</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1</td><td>400000000</td><td>1852174811</td><td>null</td><td>123723</td><td>699999</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;INDIVIDUAL&quot;</td></tr><tr><td>2</td><td>118</td><td>118</td><td>null</td><td>132</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1</td><td>22927472</td><td>34736774</td><td>1</td><td>127659</td><td>698505</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>3</td><td>31</td><td>31</td><td>null</td><td>32</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1</td><td>500000</td><td>1580106</td><td>1</td><td>204814</td><td>676543</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>4</td><td>9</td><td>9</td><td>null</td><td>9</td><td>null</td><td>null</td><td>null</td><td>null</td><td>547</td><td>500000</td><td>533182</td><td>1</td><td>254137</td><td>666545</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>5</td><td>9</td><td>9</td><td>null</td><td>9</td><td>null</td><td>null</td><td>null</td><td>null</td><td>547</td><td>500000</td><td>572448</td><td>1</td><td>307383</td><td>666545</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 21)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ alias â”† degree â”† degree_in â”† degree_out â”† â€¦ â”† cluster_num â”† cluster_nu â”† cluster_nu â”† label      â”‚\n",
       "â”‚ ---   â”† ---    â”† ---       â”† ---        â”†   â”† _edges      â”† m_cc       â”† m_nodes_in â”† ---        â”‚\n",
       "â”‚ i64   â”† i32    â”† i32       â”† i32        â”†   â”† ---         â”† ---        â”† _cc        â”† str        â”‚\n",
       "â”‚       â”†        â”†           â”†            â”†   â”† i32         â”† i32        â”† ---        â”†            â”‚\n",
       "â”‚       â”†        â”†           â”†            â”†   â”†             â”†            â”† i32        â”†            â”‚\n",
       "â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ 1     â”† 920    â”† 920       â”† null       â”† â€¦ â”† null        â”† null       â”† null       â”† INDIVIDUAL â”‚\n",
       "â”‚ 2     â”† 118    â”† 118       â”† null       â”† â€¦ â”† null        â”† null       â”† null       â”† null       â”‚\n",
       "â”‚ 3     â”† 31     â”† 31        â”† null       â”† â€¦ â”† null        â”† null       â”† null       â”† null       â”‚\n",
       "â”‚ 4     â”† 9      â”† 9         â”† null       â”† â€¦ â”† null        â”† null       â”† null       â”† null       â”‚\n",
       "â”‚ 5     â”† 9      â”† 9         â”† null       â”† â€¦ â”† null        â”† null       â”† null       â”† null       â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pl.read_parquet(\"../data/BTCGraph/node_features.parquet\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(252219007, 21)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot select columns using key of type 'Expr': <Expr ['col(\"label\").is_null()'] at 0x106468D00>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/Projects/G2007/code/L2GX/.venv/lib/python3.10/site-packages/polars/_utils/getitem.py:167\u001b[0m, in \u001b[0;36mget_df_item_by_key\u001b[0;34m(df, key)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_select_rows\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "File \u001b[0;32m~/Projects/G2007/code/L2GX/.venv/lib/python3.10/site-packages/polars/_utils/getitem.py:326\u001b[0m, in \u001b[0;36m_select_rows\u001b[0;34m(df, key)\u001b[0m\n\u001b[1;32m    325\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot select rows using key of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(key)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 326\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot select rows using key of type 'Expr': <Expr ['col(\"label\").is_null()'] at 0x106468D00>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sdf \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_null\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/Projects/G2007/code/L2GX/.venv/lib/python3.10/site-packages/polars/dataframe/frame.py:1363\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\n\u001b[1;32m   1227\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1228\u001b[0m     key: (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     ),\n\u001b[1;32m   1238\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series \u001b[38;5;241m|\u001b[39m Any:\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;124;03m    Get part of the DataFrame as a new DataFrame, Series, or scalar.\u001b[39;00m\n\u001b[1;32m   1241\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1361\u001b[0m \u001b[38;5;124;03m    â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜\u001b[39;00m\n\u001b[1;32m   1362\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1363\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_df_item_by_key\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/G2007/code/L2GX/.venv/lib/python3.10/site-packages/polars/_utils/getitem.py:169\u001b[0m, in \u001b[0;36mget_df_item_by_key\u001b[0;34m(df, key)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _select_rows(df, key)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_select_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/G2007/code/L2GX/.venv/lib/python3.10/site-packages/polars/_utils/getitem.py:258\u001b[0m, in \u001b[0;36m_select_columns\u001b[0;34m(df, key)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m    257\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot select columns using key of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(key)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 258\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot select columns using key of type 'Expr': <Expr ['col(\"label\").is_null()'] at 0x106468D00>"
     ]
    }
   ],
   "source": [
    "sdf = df[pl.col('label').is_null()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "edf = pl.read_parquet(\"../data/BTCGraph/transaction_edges.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load manageable sample \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m btc \u001b[38;5;241m=\u001b[39m \u001b[43mget_dataset\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbtc\u001b[39m\u001b[38;5;124m\"\u001b[39m, max_nodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Get the data\u001b[39;00m\n\u001b[1;32m      5\u001b[0m data \u001b[38;5;241m=\u001b[39m btc[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# Load manageable sample \n",
    "btc = get_dataset(\"btc\", max_nodes=10000)\n",
    "\n",
    "# Get the data\n",
    "data = btc[0]\n",
    "print(f\"Nodes: {data.num_nodes}, Features: {data.x.shape}\")\n",
    "print(f\"Classes: {data.num_classes}\")\n",
    "print(f\"Labels: {data.label_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>a</th><th>b</th><th>reveal</th><th>last_seen</th><th>total</th><th>min_sent</th><th>max_sent</th><th>total_sent</th></tr><tr><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>10</td><td>769</td><td>170</td><td>170</td><td>1</td><td>1000000000</td><td>1000000000</td><td>1000000000</td></tr><tr><td>10</td><td>184</td><td>181</td><td>181</td><td>1</td><td>1000000000</td><td>1000000000</td><td>1000000000</td></tr><tr><td>10</td><td>186</td><td>182</td><td>182</td><td>1</td><td>100000000</td><td>100000000</td><td>100000000</td></tr><tr><td>10</td><td>188</td><td>183</td><td>183</td><td>1</td><td>100000000</td><td>100000000</td><td>100000000</td></tr><tr><td>10</td><td>259</td><td>248</td><td>248</td><td>1</td><td>1000000000</td><td>1000000000</td><td>1000000000</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 8)\n",
       "â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ a   â”† b   â”† reveal â”† last_seen â”† total â”† min_sent   â”† max_sent   â”† total_sent â”‚\n",
       "â”‚ --- â”† --- â”† ---    â”† ---       â”† ---   â”† ---        â”† ---        â”† ---        â”‚\n",
       "â”‚ i32 â”† i32 â”† i32    â”† i32       â”† i32   â”† i64        â”† i64        â”† i64        â”‚\n",
       "â•â•â•â•â•â•â•ªâ•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ 10  â”† 769 â”† 170    â”† 170       â”† 1     â”† 1000000000 â”† 1000000000 â”† 1000000000 â”‚\n",
       "â”‚ 10  â”† 184 â”† 181    â”† 181       â”† 1     â”† 1000000000 â”† 1000000000 â”† 1000000000 â”‚\n",
       "â”‚ 10  â”† 186 â”† 182    â”† 182       â”† 1     â”† 100000000  â”† 100000000  â”† 100000000  â”‚\n",
       "â”‚ 10  â”† 188 â”† 183    â”† 183       â”† 1     â”† 100000000  â”† 100000000  â”† 100000000  â”‚\n",
       "â”‚ 10  â”† 259 â”† 248    â”† 248       â”† 1     â”† 1000000000 â”† 1000000000 â”† 1000000000 â”‚\n",
       "â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal data\n",
    "# as733 = get_dataset(\"as-733\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <a id='chapter3'> ğŸŒ <font color=\"grey\">Graphs </font></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```TGraph``` is a wrapper for torch-geometric ```Data``` objects. These include, among other things, methods for fast adjacency look-up and various optimizations. These are mostly used when performing graph clustering and generating patches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from l2gx.graphs import TGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tg = TGraph(cora[0].edge_index, edge_attr=cora[0].edge_attr, x=cora[0].x)\n",
    "print(tg.adj_index)\n",
    "print(tg.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a future iteration one can think about consolidating this part by having graphs represented in some existing graph package like Raphtory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <a id='chapter4'> ğŸ§© <font color=\"grey\">Patches </font></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A patch can equivalently refer to a subgraph or to an embedding of this subgraph. As a set of points, a patch is represented using the ```Patch``` class. A ```Patch``` object has the properties ```nodes```, ```index``` and ```coordinates```. ```nodes``` is simply a list of the nodes from the original graph that are present in the patch. ```index``` is a dict that maps each node to an index into ```coordinates```, which is just a list of coordinates. For example, if a graph embedding consists of four nodes in two dimensions as follows, and a patch is represented by the solid circles, then the corresponding object would have the following properties:\n",
    "\n",
    "![Patch](./images/square_patch.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from l2gx.patch.patches import Patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Patch([0, 2, 3], np.array([[0.0, 0.0], [1.0, 0.0], [1.0, 1.0]]))\n",
    "print(f\"Coordinates: {p.coordinates[0]}, {p.coordinates[1]}, {p.coordinates[2]}\")\n",
    "print(f\"Nodes (with noden numbering from original graph): {p.nodes}\")\n",
    "print(f\"Index dictionary: {p.index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from l2gx.patch import create_patches\n",
    "from run.plots import plot_patch_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = TGraph(tg_cora.edge_index, edge_attr=tg_cora.edge_attr, x=tg_cora.x)\n",
    "patch_graph = create_patches(graph, num_patches=10, clustering_method=\"metis\")\n",
    "patches = patch_graph.patches\n",
    "overlap_nodes = patch_graph.overlap_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The patches from the nodes of a **patch graph**, where two nodes are connected by an edge if the patches contain overlapping nodes. The alignment tasks consists of making the correponding coordinates overlap as much as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([len(p.nodes) for p in patches])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_patch_graph(patch_graph, tg, filename=None)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <a id='chapter5'> ğŸ¯ <font color=\"grey\">Embedding </font></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The L2GX framework implements several graph embedding methods: ```SVDEmbedding```, ```GAEEmbedding```, ```VGAEEmbedding```, ```GraphSAGEEmbedding``` and ```DGIEmbedding```. The first three are based on transductive learning, while the last two are inductive.\n",
    "\n",
    "* <font color=\"grey\">SVD</font> - Classical spectral approach using eigendecomposition\n",
    "* <font color=\"grey\">GAE</font> - [Graph Auto-Encoder ](https://arxiv.org/abs/1611.07308) for deterministic reconstruction\n",
    "* <font color=\"grey\">VGAE</font> - [Variational Graph Auto-Encoder](https://arxiv.org/abs/1611.07308) with probabilistic latent variables\n",
    "* <font color=\"grey\">GraphSAGE</font> - [Inductive Representation Learning on Large Graphs](https://arxiv.org/abs/1706.02216) for scalable embedding\n",
    "* <font color=\"grey\">DGI</font> - [Deep Graph Infomax](https://arxiv.org/abs/1809.10341) using self-supervised contrastive learning\n",
    "\n",
    "All methods are accessible through a unified interface with the ```get_embedding()``` function and registry system. The demonstration below shows convergence analysis, quality metrics, and UMAP visualizations for comprehensive comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from l2gx.embedding import get_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "embedder = get_embedding(\"vgae\", embedding_dim=64, epochs=200)\n",
    "embedding = embedder.fit_transform(tg_cora, verbose=False)\n",
    "end_time = time.time()\n",
    "embedding_time = end_time - start_time\n",
    "loss_history = embedder.get_training_history()\n",
    "\n",
    "print(f\"VGAE embedding completed in {embedding_time:.2f}s\")\n",
    "print(f\"   Embedding shape: {embedding.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_history['epochs'], loss_history['losses'])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"VGAE Training Loss Curve\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <a id='chapter6'> ğŸ”— <font color=\"grey\">Alignment </font></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two general alignment methods are available: ```l2g``` and ```geo```. The ```l2g``` method is essentially the original Local2Global approach, though with various options for speeding up the eigendecomposition using randomized linear algebra. The ```geo``` method is based on optimization on the orthogonal group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from example import (\n",
    "    generate_patch_graph,\n",
    "    generate_points,\n",
    "    plot_patches,\n",
    "    transform_patches,\n",
    ")\n",
    "\n",
    "from l2gx.align import get_aligner, procrustes_error\n",
    "\n",
    "rg = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test the alignment method using a synthetic point cloud in two dimensions and in 256 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = generate_points(\n",
    "    n_clusters=5, scale=1.0, std=0.2, max_size=2000, min_size=128, dim=2\n",
    ")\n",
    "pg = generate_patch_graph(\n",
    "    points,\n",
    "    sample_size=10,\n",
    "    min_degree=4,\n",
    "    min_overlap=64,\n",
    "    min_patch_size=128,\n",
    "    eps=1,\n",
    "    kmeans=False,\n",
    ")\n",
    "patches = pg.patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The patches are moved around, scaled and noise is added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_level = 0.1\n",
    "shift_scale = 10\n",
    "scale_range = [0.01, 100]\n",
    "\n",
    "# Create transformed copies of the patches\n",
    "transformed_patches = [copy.deepcopy(p) for p in patches]\n",
    "\n",
    "# Add noise to the transformed patches\n",
    "if noise_level > 0:\n",
    "    for patch in transformed_patches:\n",
    "        noise = rg.normal(loc=0, scale=noise_level, size=patch.coordinates.shape)\n",
    "        patch.coordinates += noise\n",
    "\n",
    "transformed_patches = transform_patches(\n",
    "    transformed_patches, shift_scale=shift_scale, scale_range=scale_range\n",
    ")\n",
    "transformed_pg = copy.deepcopy(pg)\n",
    "transformed_pg.patches = transformed_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_patches(patches, transformed_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2g_aligner = get_aligner(\"l2g\", randomized_method=\"randomized\", sketch_method=\"rademacher\")\n",
    "l2g_aligner.align_patches(transformed_pg)\n",
    "embedding = l2g_aligner.get_aligned_embedding()\n",
    "error = procrustes_error(embedding, points)\n",
    "print(f\"Procrustes error: {error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_patches(patches, l2g_aligner.patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# High-dimensional patches\n",
    "points = generate_points(\n",
    "    n_clusters=5, scale=1.0, std=0.2, max_size=2000, min_size=128, dim=256\n",
    ")\n",
    "pg = generate_patch_graph(\n",
    "    points,\n",
    "    sample_size=20,\n",
    "    min_degree=4,\n",
    "    min_overlap=64,\n",
    "    min_patch_size=128,\n",
    "    eps=1,\n",
    "    kmeans=False,\n",
    ")\n",
    "patches = pg.patches\n",
    "overlap_nodes = pg.overlap_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_level = 0.1\n",
    "shift_scale = 10\n",
    "scale_range = [0.01, 100]\n",
    "\n",
    "# Create transformed copies of the patches\n",
    "transformed_patches = [copy.deepcopy(p) for p in patches]\n",
    "\n",
    "# Add noise to the transformed patches\n",
    "if noise_level > 0:\n",
    "    for patch in transformed_patches:\n",
    "        noise = rg.normal(loc=0, scale=noise_level, size=patch.coordinates.shape)\n",
    "        patch.coordinates += noise\n",
    "\n",
    "transformed_patches = transform_patches(\n",
    "    transformed_patches, shift_scale=shift_scale, scale_range=scale_range\n",
    ")\n",
    "transformed_pg = copy.deepcopy(pg)\n",
    "transformed_pg.patches = transformed_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2g_aligner_standard = get_aligner(\"l2g\", randomized_method=\"standard\")\n",
    "time_start = time.time()\n",
    "l2g_aligner_standard.align_patches(transformed_pg)\n",
    "time_end = time.time()\n",
    "print(f\"Time taken: {time_end - time_start} seconds\")\n",
    "embedding_standard = l2g_aligner_standard.get_aligned_embedding()\n",
    "\n",
    "l2g_aligner_randomized = get_aligner(\n",
    "    \"l2g\", randomized_method=\"randomized\", sketch_method=\"rademacher\"\n",
    ")\n",
    "time_start = time.time()\n",
    "l2g_aligner_randomized.align_patches(transformed_pg)\n",
    "time_end = time.time()\n",
    "print(f\"Time taken: {time_end - time_start} seconds\")\n",
    "embedding_randomized = (\n",
    "    l2g_aligner_randomized.get_aligned_embedding()\n",
    ")\n",
    "\n",
    "procrustes_error_standard = procrustes_error(embedding_standard, points)\n",
    "procrustes_error_randomized = procrustes_error(embedding_randomized, points)\n",
    "\n",
    "print(f\"Procrustes error (standard): {procrustes_error_standard}\")\n",
    "print(f\"Procrustes error (randomized): {procrustes_error_randomized}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run.random_graph.roc import RandomOverlappingCommunities\n",
    "from run.random_graph.patch_integration import CommunityToPatchConverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc = RandomOverlappingCommunities(\n",
    "    n_nodes=200,\n",
    "    n_communities=8,\n",
    "    community_generation=\"preferential\",\n",
    "    average_community_size=25,\n",
    "    overlap_factor=0.3,\n",
    "    membership_strength_dist=\"beta\",\n",
    "    base_edge_prob=0.15,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "G = roc.generate_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = CommunityToPatchConverter(min_patch_size=10)\n",
    "patches = converter.communities_to_patches(graph, community_nodes, embeddings)\n",
    "patch_graph = converter.create_patch_graph(patches)\n",
    "\n",
    "aligner = get_aligner(\"l2g\")\n",
    "aligner.align_patches(patch_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <a id='chapter7'> <font color=\"grey\">7. Hierarchical alignment </font></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be done."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
