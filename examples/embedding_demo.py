"""
Graph Embedding Demonstration.

This example demonstrates all available embedding methods in the L2GX framework:

- SVD: Classical matrix factorization approach
- GAE/VGAE: Graph auto-encoders (transductive)
- GraphSAGE: Inductive neighborhood sampling
- DGI: Self-supervised mutual information maximization

"""

import numpy as np
import networkx as nx
import torch
import time
from typing import Dict, List
from l2gx.embedding import (
    get_embedding, 
    list_embeddings,
    GraphEmbedding,
    GAEEmbedding,
    VGAEEmbedding,
    SVDEmbedding,
    GraphSAGEEmbedding,
    DGIEmbedding
)


# ================================
# Graph Creation Utilities
# ================================

def create_test_graphs():
    """Create various small test graphs for demonstration."""
    graphs = {}
    
    # Small graph for quick testing
    graphs['karate'] = nx.karate_club_graph()
    
    # Medium graph with community structure
    graphs['caveman'] = nx.caveman_graph(4, 8)
    
    # Scale-free network
    graphs['barabasi'] = nx.barabasi_albert_graph(100, 3, seed=42)
    
    # Random graph
    graphs['erdos'] = nx.erdos_renyi_graph(80, 0.1, seed=42)
    
    # Path graph (simple structure)
    graphs['path'] = nx.path_graph(30)
    
    return graphs


def create_inductive_test_graphs():
    """Create training and extended graphs for inductive learning demonstration."""
    # Create base training graph
    G_train = nx.karate_club_graph()
    
    # Create extended graph with new nodes
    G_extended = G_train.copy()
    new_nodes = list(range(G_train.number_of_nodes(), G_train.number_of_nodes() + 10))
    G_extended.add_nodes_from(new_nodes)
    
    # Connect new nodes to existing nodes
    np.random.seed(42)
    for new_node in new_nodes:
        num_connections = np.random.randint(2, 4)
        existing_nodes = np.random.choice(G_train.number_of_nodes(), num_connections, replace=False)
        for existing_node in existing_nodes:
            G_extended.add_edge(new_node, existing_node)
    
    return G_train, G_extended, new_nodes


# ================================
# Basic Interface Demonstrations
# ================================

def demonstrate_unified_interface():
    """Demonstrate the unified embedding interface and registry system."""
    print("ğŸš€ UNIFIED EMBEDDING INTERFACE DEMONSTRATION")
    print("=" * 60)
    
    # Show available methods
    methods = list_embeddings()
    print(f"ğŸ“‹ Available embedding methods: {methods}")
    print()
    
    # Create sample graph
    G = nx.karate_club_graph()
    print(f"ğŸ“Š Test graph: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges")
    print()
    
    embedding_dim = 16
    
    # Method 1: Registry interface
    print("ğŸ”§ Method 1: Using Registry Interface")
    svd_emb = get_embedding('svd', embedding_dim=embedding_dim)
    embeddings = svd_emb.fit_transform(G)
    print(f"   SVD embeddings shape: {embeddings.shape}")
    print(f"   SVD parameters: {svd_emb.get_params()}")
    print()
    
    # Method 2: Direct instantiation
    print("ğŸ”§ Method 2: Direct Instantiation")
    gae_emb = GAEEmbedding(embedding_dim=embedding_dim, epochs=20, hidden_dim=32)
    print(f"   GAE embedding: {gae_emb}")
    print(f"   Is fitted before training: {gae_emb.is_fitted}")
    
    gae_embeddings = gae_emb.fit_transform(G)
    print(f"   GAE embeddings shape: {gae_embeddings.shape}")
    print(f"   Is fitted after training: {gae_emb.is_fitted}")
    print()
    
    # Method 3: Using aliases
    print("ğŸ”§ Method 3: Using Method Aliases")
    aliases_demo = {
        'variational_gae': 'vgae',
        'sage': 'graphsage', 
        'deep_graph_infomax': 'dgi'
    }
    
    for alias, method in aliases_demo.items():
        try:
            emb = get_embedding(alias, embedding_dim=8, epochs=10)
            embeddings = emb.fit_transform(G)
            print(f"   {alias} â†’ {method}: {embeddings.shape}")
        except Exception as e:
            print(f"   {alias} â†’ {method}: Failed - {e}")
    print()
    
    # Method 4: Parameter modification
    print("ğŸ”§ Method 4: Parameter Modification")
    svd_emb.set_params(embedding_dim=8, matrix_type='laplacian')
    modified_embeddings = svd_emb.fit_transform(G)
    print(f"   Modified SVD embeddings shape: {modified_embeddings.shape}")
    print(f"   Updated parameters: {svd_emb.get_params()}")
    print()
    
    return {
        'svd': embeddings,
        'gae': gae_embeddings,
        'svd_modified': modified_embeddings
    }


def demonstrate_polymorphism():
    """Demonstrate polymorphic usage of embedding methods."""
    print("ğŸ”„ POLYMORPHIC USAGE DEMONSTRATION")
    print("=" * 60)
    
    G = nx.karate_club_graph()
    methods = ['svd', 'gae', 'vgae', 'graphsage', 'dgi']
    
    def embed_with_method(method_name: str, graph, dim: int = 8) -> np.ndarray:
        """Generic function that works with any embedding method."""
        if method_name in ['gae', 'vgae', 'graphsage', 'dgi']:
            embedding = get_embedding(method_name, embedding_dim=dim, epochs=15)
        else:
            embedding = get_embedding(method_name, embedding_dim=dim)
        
        return embedding.fit_transform(graph)
    
    results = {}
    for method in methods:
        try:
            embeddings = embed_with_method(method, G)
            results[method] = embeddings
            print(f"âœ… {method.upper()}: {embeddings.shape}")
        except Exception as e:
            print(f"âŒ {method.upper()}: Failed - {e}")
    
    print()
    return results


# ================================
# Method-Specific Demonstrations
# ================================

def demonstrate_svd_variants():
    """Demonstrate SVD embedding with different matrix types."""
    print("ğŸ“ SVD EMBEDDING VARIANTS")
    print("=" * 60)
    
    G = nx.karate_club_graph()
    matrix_types = ['adjacency', 'laplacian', 'normalized']
    
    for matrix_type in matrix_types:
        try:
            svd = SVDEmbedding(embedding_dim=16, matrix_type=matrix_type)
            embeddings = svd.fit_transform(G)
            
            # Analyze embedding properties
            mean_norm = np.linalg.norm(embeddings, axis=1).mean()
            print(f"   {matrix_type.capitalize()} matrix: {embeddings.shape}, avg norm: {mean_norm:.4f}")
            
        except Exception as e:
            print(f"   {matrix_type.capitalize()} matrix: Failed - {e}")
    
    print()


def demonstrate_gae_architectures():
    """Demonstrate GAE/VGAE with different configurations."""
    print("ğŸ—ï¸  GAE/VGAE ARCHITECTURE VARIANTS")
    print("=" * 60)
    
    G = nx.karate_club_graph()
    
    # GAE vs VGAE
    print("ğŸ“Š GAE vs VGAE Comparison:")
    for method, name in [('gae', 'GAE'), ('vgae', 'VGAE')]:
        try:
            emb = get_embedding(method, embedding_dim=16, epochs=20, hidden_dim=32)
            embeddings = emb.fit_transform(G)
            
            mean_norm = np.linalg.norm(embeddings, axis=1).mean()
            print(f"   {name}: {embeddings.shape}, avg norm: {mean_norm:.4f}")
            
        except Exception as e:
            print(f"   {name}: Failed - {e}")
    
    # Different hidden dimensions
    print("\nğŸ”§ Hidden Dimension Impact (GAE):")
    hidden_dims = [16, 32, 64]
    for hidden_dim in hidden_dims:
        try:
            gae = GAEEmbedding(embedding_dim=16, hidden_dim=hidden_dim, epochs=15)
            embeddings = gae.fit_transform(G)
            
            mean_norm = np.linalg.norm(embeddings, axis=1).mean()
            print(f"   Hidden dim {hidden_dim}: avg norm: {mean_norm:.4f}")
            
        except Exception as e:
            print(f"   Hidden dim {hidden_dim}: Failed - {e}")
    
    print()


def demonstrate_graphsage_features():
    """Demonstrate GraphSAGE's inductive capabilities and configurations."""
    print("ğŸ¯ GRAPHSAGE INDUCTIVE LEARNING")
    print("=" * 60)
    
    # For inductive learning demonstration, we'll use a simpler approach
    # that doesn't require complex graph extension
    G_train = nx.karate_club_graph()
    
    print(f"ğŸ“Š Training graph: {G_train.number_of_nodes()} nodes, {G_train.number_of_edges()} edges")
    print()
    
    # Train GraphSAGE on training graph
    print("ğŸš€ Training GraphSAGE...")
    sage = GraphSAGEEmbedding(embedding_dim=32, epochs=30, hidden_dim=64)
    sage.fit(G_train)
    
    # Test basic capabilities
    print("ğŸ”® Testing GraphSAGE capabilities...")
    
    # Get embeddings for training nodes
    train_embeddings = sage.transform(G_train)
    print(f"   Training embeddings: {train_embeddings.shape}")
    
    # Test that the model can handle the same graph multiple times
    train_embeddings2 = sage.transform(G_train)
    consistency = np.allclose(train_embeddings, train_embeddings2, atol=1e-6)
    print(f"   Consistency check: {'âœ… Pass' if consistency else 'âŒ Fail'}")
    
    # Test different aggregators
    print("\nğŸ”§ GraphSAGE Aggregator Comparison:")
    aggregators = ['mean', 'max']  # 'lstm' requires more complex setup
    
    for aggregator in aggregators:
        try:
            sage_agg = GraphSAGEEmbedding(
                embedding_dim=16, 
                aggregator=aggregator, 
                epochs=15
            )
            embeddings = sage_agg.fit_transform(G_train)
            mean_norm = np.linalg.norm(embeddings, axis=1).mean()
            print(f"   {aggregator.capitalize()} aggregator: avg norm: {mean_norm:.4f}")
            
        except Exception as e:
            print(f"   {aggregator.capitalize()} aggregator: Failed - {e}")
    
    # Demonstrate inductive capability with a note
    print("\nğŸ’¡ Note: GraphSAGE supports inductive learning through its")
    print("   transform_new_nodes() method, which can embed new nodes")
    print("   that weren't seen during training by using their neighborhood.")
    
    print()
    return sage, train_embeddings, train_embeddings


def demonstrate_dgi_features():
    """Demonstrate DGI's self-supervised learning and encoder variants."""
    print("ğŸ§  DGI SELF-SUPERVISED LEARNING")
    print("=" * 60)
    
    G = nx.karate_club_graph()
    
    # Basic DGI demonstration
    print("ğŸš€ Basic DGI Training:")
    dgi = DGIEmbedding(embedding_dim=32, epochs=30, encoder_type='gcn')
    embeddings = dgi.fit_transform(G)
    summary = dgi.get_graph_summary(G)
    
    print(f"   Node embeddings: {embeddings.shape}")
    print(f"   Graph summary: {summary.shape}")
    print(f"   Summary norm: {np.linalg.norm(summary):.4f}")
    print()
    
    # Encoder architecture comparison
    print("ğŸ—ï¸  DGI Encoder Architecture Comparison:")
    encoders = ['gcn', 'gat', 'sage']
    
    for encoder in encoders:
        try:
            dgi_enc = DGIEmbedding(
                embedding_dim=16, 
                encoder_type=encoder, 
                epochs=20
            )
            embeddings = dgi_enc.fit_transform(G)
            mean_norm = np.linalg.norm(embeddings, axis=1).mean()
            print(f"   {encoder.upper()} encoder: avg norm: {mean_norm:.4f}")
            
        except Exception as e:
            print(f"   {encoder.upper()} encoder: Failed - {e}")
    
    # Readout function comparison
    print("\nğŸ“Š DGI Readout Function Comparison:")
    readouts = ['mean', 'max', 'sum']
    
    for readout in readouts:
        try:
            dgi_read = DGIEmbedding(
                embedding_dim=16, 
                readout_type=readout, 
                epochs=15
            )
            dgi_read.fit(G)
            summary = dgi_read.get_graph_summary(G)
            print(f"   {readout.capitalize()} readout: summary norm: {np.linalg.norm(summary):.4f}")
            
        except Exception as e:
            print(f"   {readout.capitalize()} readout: Failed - {e}")
    
    print()
    return dgi, embeddings, summary


# ================================
# Analysis and Comparison
# ================================

def analyze_embeddings(embeddings: np.ndarray, title: str = "Embeddings"):
    """Analyze embedding properties and quality."""
    print(f"ğŸ“ˆ {title} Analysis:")
    print(f"   Shape: {embeddings.shape}")
    print(f"   Mean: {embeddings.mean():.4f}")
    print(f"   Std: {embeddings.std():.4f}")
    print(f"   Min: {embeddings.min():.4f}")
    print(f"   Max: {embeddings.max():.4f}")
    
    # Compute norms
    norms = np.linalg.norm(embeddings, axis=1)
    print(f"   Average L2 norm: {norms.mean():.4f}")
    print(f"   Norm std: {norms.std():.4f}")
    
    # Check for issues
    has_nan = np.isnan(embeddings).any()
    has_inf = np.isinf(embeddings).any()
    has_zero = (norms == 0).any()
    
    print(f"   Quality checks: NaN: {'âŒ' if has_nan else 'âœ…'}, "
          f"Inf: {'âŒ' if has_inf else 'âœ…'}, "
          f"Zero vectors: {'âŒ' if has_zero else 'âœ…'}")
    
    # Embedding diversity (for small graphs)
    if embeddings.shape[0] <= 50:
        from scipy.spatial.distance import pdist
        distances = pdist(embeddings, metric='cosine')
        print(f"   Average cosine distance: {distances.mean():.4f}")
    
    print()


def comprehensive_method_comparison():
    """Compare all embedding methods on the same graph."""
    print("âš”ï¸  COMPREHENSIVE METHOD COMPARISON")
    print("=" * 60)
    
    G = nx.karate_club_graph()
    embedding_dim = 16
    methods = ['svd', 'gae', 'vgae', 'graphsage', 'dgi']
    results = {}
    
    print(f"ğŸ“Š Test graph: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges")
    print(f"ğŸ¯ Target embedding dimension: {embedding_dim}")
    print()
    
    for method in methods:
        print(f"ğŸ§ª Testing {method.upper()}...")
        try:
            start_time = time.time()
            
            if method in ['gae', 'vgae', 'graphsage', 'dgi']:
                embedding = get_embedding(method, 
                                        embedding_dim=embedding_dim, 
                                        epochs=25)
            else:
                embedding = get_embedding(method, embedding_dim=embedding_dim)
            
            embeddings = embedding.fit_transform(G)
            end_time = time.time()
            
            results[method] = embeddings
            
            # Analysis
            mean_norm = np.linalg.norm(embeddings, axis=1).mean()
            training_time = end_time - start_time
            is_inductive = hasattr(embedding, 'transform_new_nodes')
            
            print(f"   âœ… Success: {embeddings.shape}")
            print(f"   ğŸ“ Average norm: {mean_norm:.4f}")
            print(f"   â±ï¸  Training time: {training_time:.2f}s")
            print(f"   ğŸ”„ Inductive: {'Yes' if is_inductive else 'No'}")
            print(f"   ğŸ·ï¸  Type: {type(embedding).__name__}")
            
        except Exception as e:
            print(f"   âŒ Failed: {e}")
        
        print()
    
    return results


def scalability_test():
    """Test embedding methods on graphs of different sizes."""
    print("ğŸ“ˆ SCALABILITY TESTING")
    print("=" * 60)
    
    graphs = create_test_graphs()
    methods = ['svd', 'graphsage', 'dgi']  # Fast methods for scalability test
    
    for name, graph in graphs.items():
        print(f"ğŸ“Š Testing on {name} graph ({graph.number_of_nodes()} nodes, {graph.number_of_edges()} edges):")
        
        for method in methods:
            try:
                start_time = time.time()
                
                if method in ['graphsage', 'dgi']:
                    emb = get_embedding(method, embedding_dim=16, epochs=10)
                else:
                    emb = get_embedding(method, embedding_dim=16)
                
                embeddings = emb.fit_transform(graph)
                end_time = time.time()
                
                mean_norm = np.linalg.norm(embeddings, axis=1).mean()
                print(f"   {method.upper()}: {embeddings.shape}, {end_time - start_time:.2f}s, norm: {mean_norm:.4f}")
                
            except Exception as e:
                print(f"   {method.upper()}: Failed - {e}")
        
        print()


# ================================
# Main Demonstration Runner
# ================================

def run_comprehensive_demo():
    """Run the complete embedding demonstration."""
    print("ğŸ‰ L2GX COMPREHENSIVE EMBEDDING DEMONSTRATION")
    print("=" * 80)
    print()
    
    # Set random seeds for reproducibility
    np.random.seed(42)
    torch.manual_seed(42)
    
    try:
        # 1. Basic interface demonstrations
        print("PART 1: BASIC INTERFACE & REGISTRY")
        print("-" * 40)
        basic_results = demonstrate_unified_interface()
        poly_results = demonstrate_polymorphism()
        
        # 2. Method-specific features
        print("PART 2: METHOD-SPECIFIC FEATURES")
        print("-" * 40)
        demonstrate_svd_variants()
        demonstrate_gae_architectures()
        sage, train_emb, _ = demonstrate_graphsage_features()
        dgi, dgi_emb, dgi_summary = demonstrate_dgi_features()
        
        # 3. Analysis and comparison
        print("PART 3: ANALYSIS & COMPARISON")
        print("-" * 40)
        
        # Analyze some embeddings
        analyze_embeddings(basic_results['svd'], "SVD Embeddings")
        analyze_embeddings(train_emb, "GraphSAGE Training Embeddings")
        # Note: GraphSAGE analysis already done in method-specific section
        analyze_embeddings(dgi_emb, "DGI Node Embeddings")
        
        # Comprehensive comparison
        comparison_results = comprehensive_method_comparison()
        
        # 4. Scalability testing
        print("PART 4: SCALABILITY TESTING")
        print("-" * 40)
        scalability_test()
        
        # Summary
        print("ğŸŠ DEMONSTRATION SUMMARY")
        print("=" * 60)
        print("âœ… Successfully demonstrated:")
        print("   â€¢ Unified embedding interface with registry system")
        print("   â€¢ All 5 embedding methods: SVD, GAE, VGAE, GraphSAGE, DGI")
        print("   â€¢ Method-specific configurations and capabilities")
        print("   â€¢ Inductive vs transductive learning paradigms")
        print("   â€¢ Parameter management and modification")
        print("   â€¢ Embedding analysis and quality assessment")
        print("   â€¢ Performance comparison and scalability testing")
        print()
        print("ğŸš€ The L2GX embedding framework is ready for production use!")
        
        return {
            'basic': basic_results,
            'comparison': comparison_results,
            'graphsage': train_emb,
            'dgi': dgi_emb,
            'dgi_summary': dgi_summary
        }
        
    except Exception as e:
        print(f"âŒ Demo failed with error: {e}")
        import traceback
        traceback.print_exc()
        return None


if __name__ == "__main__":
    results = run_comprehensive_demo()